{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 6 Exercise 1: Non-Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "We return to the MNIST data set on handwritten digits to compare non-linear classification algorithms ...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the full MNIST data set contains 70k samples of digits 0-9 as 28*28 gray scale images (represented as 784 dim vectors)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at max/min value in the data\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the data for the first test the the computing ist faster\n",
    "X= X[:3000,:]\n",
    "y= y[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.1: Cross-Validation and Support Vector Machines\n",
    "Train and optimize  C-SVM classifier on MNIST (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "* use a RBF kernel\n",
    "* use *random search* with cross-validation to find the best settings for *gamma* and *C* (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=40).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#RBF Kernel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_svm = SVC(C = 3.0, kernel='rbf', gamma = 'auto', max_iter=40, random_state=42)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "clf_svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 30 is smaller than n_iter=40. Running 30 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVC(), n_iter=40, n_jobs=4,\n",
       "                   param_distributions={'C': [0.1, 1, 2, 7, 20, 50],\n",
       "                                        'gamma': [0.1, 0.5, 1, 10, 'scale']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# random search with cross validation for C and gamma\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# build a classifier\n",
    "clf_svm2 = SVC()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'C': np.linspace(0,50 ,num=10),\n",
    "              'gamma':np.linspace(0.1,10,num=10)}\n",
    "\n",
    "param_2= dict(C=[0.1,1,2,7,20,50],gamma=[0.1,0.5,1,10,'scale']) #create search space\n",
    "\n",
    "# run randomized search, cv= crossvalidation\n",
    "random_search = RandomizedSearchCV(estimator=clf_svm2, param_distributions=param_2,\n",
    "                                   n_iter=40 , cv=5, n_jobs=4)\n",
    "random_search.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.852083</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.914583</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.937083</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.937083</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C param_gamma  split0_test_score  split1_test_score  \\\n",
       "0       0.1         0.1           0.112500           0.110417   \n",
       "1       0.1         0.5           0.112500           0.110417   \n",
       "2       0.1           1           0.112500           0.110417   \n",
       "3       0.1          10           0.112500           0.110417   \n",
       "4       0.1       scale           0.852083           0.870833   \n",
       "5       1.0         0.1           0.112500           0.110417   \n",
       "6       1.0         0.5           0.112500           0.110417   \n",
       "7       1.0           1           0.112500           0.110417   \n",
       "8       1.0          10           0.112500           0.110417   \n",
       "9       1.0       scale           0.914583           0.929167   \n",
       "10      2.0         0.1           0.112500           0.110417   \n",
       "11      2.0         0.5           0.112500           0.110417   \n",
       "12      2.0           1           0.112500           0.110417   \n",
       "13      2.0          10           0.112500           0.110417   \n",
       "14      2.0       scale           0.929167           0.937500   \n",
       "15      7.0         0.1           0.112500           0.110417   \n",
       "16      7.0         0.5           0.112500           0.110417   \n",
       "17      7.0           1           0.112500           0.110417   \n",
       "18      7.0          10           0.112500           0.110417   \n",
       "19      7.0       scale           0.937500           0.935417   \n",
       "20     20.0         0.1           0.112500           0.110417   \n",
       "21     20.0         0.5           0.112500           0.110417   \n",
       "22     20.0           1           0.112500           0.110417   \n",
       "23     20.0          10           0.112500           0.110417   \n",
       "24     20.0       scale           0.937500           0.933333   \n",
       "25     50.0         0.1           0.112500           0.110417   \n",
       "26     50.0         0.5           0.112500           0.110417   \n",
       "27     50.0           1           0.112500           0.110417   \n",
       "28     50.0          10           0.112500           0.110417   \n",
       "29     50.0       scale           0.937500           0.933333   \n",
       "\n",
       "    split2_test_score  split3_test_score  mean_test_score  rank_test_score  \n",
       "0            0.112500           0.112500         0.112083              7.0  \n",
       "1            0.112500           0.112500         0.112083              7.0  \n",
       "2            0.112500           0.112500         0.112083              7.0  \n",
       "3            0.112500           0.112500         0.112083              7.0  \n",
       "4            0.868750           0.866667         0.868333              6.0  \n",
       "5            0.112500           0.112500         0.112083              7.0  \n",
       "6            0.112500           0.112500         0.112083              7.0  \n",
       "7            0.112500           0.112500         0.112083              7.0  \n",
       "8            0.112500           0.112500         0.112083              7.0  \n",
       "9            0.929167           0.910417         0.927500              5.0  \n",
       "10           0.112500           0.112500         0.112083              7.0  \n",
       "11           0.112500           0.112500         0.112083              7.0  \n",
       "12           0.112500           0.112500         0.112083              7.0  \n",
       "13           0.112500           0.112500         0.112083              7.0  \n",
       "14           0.935417           0.927083         0.936667              4.0  \n",
       "15           0.112500           0.112500         0.112083              7.0  \n",
       "16           0.112500           0.112500         0.112083              7.0  \n",
       "17           0.112500           0.112500         0.112083              7.0  \n",
       "18           0.112500           0.112500         0.112083              7.0  \n",
       "19           0.933333           0.927083         0.937500              1.0  \n",
       "20           0.112500           0.112500         0.112083              7.0  \n",
       "21           0.112500           0.112500         0.112083              7.0  \n",
       "22           0.112500           0.112500         0.112083              7.0  \n",
       "23           0.112500           0.112500         0.112083              7.0  \n",
       "24           0.933333           0.927083         0.937083              2.0  \n",
       "25           0.112500           0.112500         0.112083              7.0  \n",
       "26           0.112500           0.112500         0.112083              7.0  \n",
       "27           0.112500           0.112500         0.112083              7.0  \n",
       "28           0.112500           0.112500         0.112083              7.0  \n",
       "29           0.933333           0.927083         0.937083              2.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "random_search_results = pd.DataFrame(random_search.cv_results_,dtype='float', columns = ['param_C','param_gamma',\n",
    "                                                                      'split0_test_score','split1_test_score','split2_test_score','split3_test_score',\n",
    "                                                                      'mean_test_score','rank_test_score'])\n",
    "random_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get best parameters\n",
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 'scale', 'C': 7}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get best parameters\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.2: Pipelines and simple Neural Networks\n",
    "Split the MNIST data into  train- and test-sets and then train and evaluate a simple Multi Layer Perceptron (MLP) network. Since the non-linear activation functions of MLPs are sensitive to the scaling on the input (recall the *sigmoid* function), we need to scale all input values to [0,1] \n",
    "\n",
    "* combine all steps of your training in a SKL pipeline (https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
    "* use a SKL-scaler to scale the data (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "* MLP Parameters: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "    * use a *SGD* solver\n",
    "    * use *tanh* as activation function\n",
    "    * compare networks with 1, 2 and 3 layers, use different numbers of neurons per layer\n",
    "    * adjust training parameters *alpha* (regularization) and *learning rate* - how sensitive is the model to these parameters?\n",
    "    * Hint: do not change all parameters at the same time, split into several experiments\n",
    "* How hard is it to find the best parameters? How many experiments would you need to find the best parameters?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline with Scaler and MLP\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#create the pipeline\n",
    "#Change the number of Neurons, layers 3\n",
    "clf_pipe10 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,16),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe11 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,32),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe12 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe13 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,128),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe14 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,256),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe15 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,1024),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe16 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,2048),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "\n",
    "#Change the Layers\n",
    "clf_pipe20 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(1,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe21 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(2,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe22 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe23 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(10,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe24 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(100,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "\n",
    "#Change the learning_rate\n",
    "clf_pipe30 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe31 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.0001,learning_rate='invscaling', activation ='tanh',solver='sgd'))\n",
    "clf_pipe32 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.0001,learning_rate='adaptive', activation ='tanh',solver='sgd'))\n",
    "\n",
    "#changing alpha\n",
    "clf_pipe40 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.0001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe41 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.0005,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe42 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.001,learning_rate='constant', activation ='tanh',solver='sgd'))\n",
    "clf_pipe43 = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(3,64),alpha=0.01,learning_rate='constant', activation ='tanh',solver='sgd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(activation='tanh', alpha=0.01,\n",
       "                               hidden_layer_sizes=(3, 64), solver='sgd'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Change Neurons\n",
    "clf_pipe10.fit(X_train,y_train)\n",
    "clf_pipe11.fit(X_train,y_train)\n",
    "clf_pipe12.fit(X_train,y_train)\n",
    "clf_pipe13.fit(X_train,y_train)\n",
    "clf_pipe14.fit(X_train,y_train)\n",
    "clf_pipe15.fit(X_train,y_train)\n",
    "clf_pipe16.fit(X_train,y_train)\n",
    "\n",
    "# Change Layers\n",
    "clf_pipe20.fit(X_train,y_train)\n",
    "clf_pipe21.fit(X_train,y_train)\n",
    "clf_pipe22.fit(X_train,y_train)\n",
    "clf_pipe23.fit(X_train,y_train)\n",
    "clf_pipe24.fit(X_train,y_train)\n",
    "\n",
    "#change learning_rate\n",
    "clf_pipe30.fit(X_train,y_train)\n",
    "clf_pipe31.fit(X_train,y_train)\n",
    "clf_pipe32.fit(X_train,y_train)\n",
    "\n",
    "# Change alpha\n",
    "clf_pipe40.fit(X_train,y_train)\n",
    "clf_pipe41.fit(X_train,y_train)\n",
    "clf_pipe42.fit(X_train,y_train)\n",
    "clf_pipe43.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Layer, Changing Neurons:\n",
      " 16 Neurons:    0.66\n",
      " 32 Neurons:    0.6433333333333333\n",
      " 64 Neurons:    0.68\n",
      " 128 Neurons:   0.7133333333333334\n",
      " 256 Neurons:   0.71\n",
      " 1024 Neurons:  0.6933333333333334\n",
      " 2048 Neurons:  0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"3 Layer, Changing Neurons:\")\n",
    "print(\" 16 Neurons:   \",clf_pipe10.score(X_test,y_test))\n",
    "print(\" 32 Neurons:   \",clf_pipe11.score(X_test,y_test))\n",
    "print(\" 64 Neurons:   \",clf_pipe12.score(X_test,y_test))\n",
    "print(\" 128 Neurons:  \",clf_pipe13.score(X_test,y_test))\n",
    "print(\" 256 Neurons:  \",clf_pipe14.score(X_test,y_test))\n",
    "print(\" 1024 Neurons: \",clf_pipe15.score(X_test,y_test))\n",
    "print(\" 2048 Neurons: \",clf_pipe16.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Neurons changing Layers:\n",
      " 1 Layer:    0.34\n",
      " 2 Layer:    0.4633333333333333\n",
      " 3 Layer:    0.69\n",
      " 10 Layer:   0.86\n",
      " 100 Layer:  0.8966666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"64 Neurons changing Layers:\")\n",
    "print(\" 1 Layer:   \",clf_pipe20.score(X_test,y_test))\n",
    "print(\" 2 Layer:   \",clf_pipe21.score(X_test,y_test))\n",
    "print(\" 3 Layer:   \",clf_pipe22.score(X_test,y_test))\n",
    "print(\" 10 Layer:  \",clf_pipe23.score(X_test,y_test))\n",
    "print(\" 100 Layer: \",clf_pipe24.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Layer, 64 Neurons, Changing learning_rate:\n",
      " constant:      0.6933333333333334\n",
      " invscaling:    0.11333333333333333\n",
      " adaptive:      0.7066666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"3 Layer, 64 Neurons, Changing learning_rate:\")\n",
    "print(\" constant:     \",clf_pipe30.score(X_test,y_test))\n",
    "print(\" invscaling:   \",clf_pipe31.score(X_test,y_test))\n",
    "print(\" adaptive:     \",clf_pipe32.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Layer, 64 Neurons, Changing alpha:\n",
      "alpha= 0.0001:  0.34\n",
      "alpha= 0.0005:  0.4633333333333333\n",
      "alpha= 0.001:   0.69\n",
      "alpha= 0.01:     0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"3 Layer, 64 Neurons, Changing alpha:\")\n",
    "print(\"alpha= 0.0001: \",clf_pipe20.score(X_test,y_test))\n",
    "print(\"alpha= 0.0005: \",clf_pipe21.score(X_test,y_test))\n",
    "print(\"alpha= 0.001:  \",clf_pipe22.score(X_test,y_test))\n",
    "print(\"alpha= 0.01:    \",clf_pipe23.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myguu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9033333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Maybe good combination\n",
    "clf_pipe = make_pipeline(StandardScaler(),MLPClassifier(hidden_layer_sizes=(100,64),alpha=0.01,learning_rate='adaptive', activation ='tanh',solver='sgd'))\n",
    "clf_pipe.fit(X_train,y_train)\n",
    "clf_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
