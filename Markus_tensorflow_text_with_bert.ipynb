{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_text_with_bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb4espuLKJiA"
      },
      "source": [
        "# Textclassification\n",
        "\n",
        "Hauptquelle : https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yivOsKpRlfM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "qa6Z4YodRXvA",
        "outputId": "9f77b92b-1e08-4b84-99f2-04a315469eb6"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "print(\"Choose the kaggel.jason file on your computer\")\n",
        "files.upload() "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choose the kaggel.jason file on your computer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e893013f-f377-4c95-9b9b-c2d32a0bdee0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e893013f-f377-4c95-9b9b-c2d32a0bdee0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"markusobert\",\"key\":\"bf8bdd6dd36b298ff3651198bb29ffab\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpL_GnspRXsf",
        "outputId": "eb988a6c-7b1b-48d5-8160-b43e5787b085"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "#! kaggle datasets list\n",
        "! pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "# Download of the data from kaggle\n",
        "! kaggle competitions download -c retail-products-classification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 2.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73052 sha256=1bf45934a9554b5959de46579aa5ba6f0dc821bcf44e1467803aa931d25f50e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n",
            "Downloading retail-products-classification.zip to /content\n",
            "100% 259M/259M [00:09<00:00, 27.2MB/s]\n",
            "100% 259M/259M [00:09<00:00, 27.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkOYSHfORXpw"
      },
      "source": [
        "# Create a directory and unzip the files there\n",
        "! mkdir retail-products-classification\n",
        "! unzip retail-products-classification.zip -d retail-products-classification &> /dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-CJ39XIRXm_"
      },
      "source": [
        "CATEGORIES = ['Electronics', \n",
        "              'Sports & Outdoors',\n",
        "              'Cell Phones & Accessories',\n",
        "              'Automotive', 'Toys & Games',\n",
        "              'Tools & Home Improvement', \n",
        "              'Health & Personal Care', \n",
        "              'Beauty',\n",
        "              'Grocery & Gourmet Food', \n",
        "              'Office Products',\n",
        "              'Arts, Crafts & Sewing',\n",
        "              'Pet Supplies', \n",
        "              'Patio, Lawn & Garden',\n",
        "              'Clothing, Shoes & Jewelry', \n",
        "              'Baby',\n",
        "              'Musical Instruments',\n",
        "              'Industrial & Scientific', \n",
        "              'Baby Products',\n",
        "              'Appliances',\n",
        "              'All Beauty',\n",
        "              'All Electronics']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "-J-WTP9PRXjw",
        "outputId": "93da81f8-2722-4cff-bec3-cbd3b4265f4b"
      },
      "source": [
        "data = pd.read_csv('retail-products-classification/train.csv')\n",
        "#pid = list(data['ImgId'])\n",
        "#descriptions = list(data['description'])\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImgId</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B000HYL1V6</td>\n",
              "      <td>TUNGSTEN SOLDER PICK WITH HANDLE</td>\n",
              "      <td>Solder Pick for picking up molten solder when ...</td>\n",
              "      <td>Arts, Crafts &amp; Sewing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B00006HXWY</td>\n",
              "      <td>Write Right 98167 Screen Protector for Sony T615C</td>\n",
              "      <td>We all screen. And we all need to protect thos...</td>\n",
              "      <td>Cell Phones &amp; Accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000GAWSBS</td>\n",
              "      <td>Casio Mens DBC310-1 Databank 300 Digital Watch...</td>\n",
              "      <td>Bringing you precision at a glance, the Casio ...</td>\n",
              "      <td>Clothing, Shoes &amp; Jewelry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000040JOL</td>\n",
              "      <td>Factory-Reconditioned DEWALT DW260KR Heavy-Dut...</td>\n",
              "      <td>Factory-Reconditioned DEWALT DW260KR Heavy-Dut...</td>\n",
              "      <td>Tools &amp; Home Improvement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00006IB78</td>\n",
              "      <td>Energizer 2 in 1 Light</td>\n",
              "      <td>This twoway light features a bright flashlight...</td>\n",
              "      <td>Health &amp; Personal Care</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ImgId  ...                 categories\n",
              "0  B000HYL1V6  ...      Arts, Crafts & Sewing\n",
              "1  B00006HXWY  ...  Cell Phones & Accessories\n",
              "2  B000GAWSBS  ...  Clothing, Shoes & Jewelry\n",
              "3  B000040JOL  ...   Tools & Home Improvement\n",
              "4  B00006IB78  ...     Health & Personal Care\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "rfuF1ISrRXg8",
        "outputId": "7ac66e10-c4b9-426d-90d6-3a73d68f7779"
      },
      "source": [
        "#Creating pandas dataframe with merged description\n",
        "data_merge = pd.DataFrame({'ImgId':data['ImgId'],\n",
        "                        'description':data['title']+\" \"+data['description'],\n",
        "                        'categories':data['categories']})\n",
        "data_merge.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImgId</th>\n",
              "      <th>description</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B000HYL1V6</td>\n",
              "      <td>TUNGSTEN SOLDER PICK WITH HANDLE Solder Pick f...</td>\n",
              "      <td>Arts, Crafts &amp; Sewing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B00006HXWY</td>\n",
              "      <td>Write Right 98167 Screen Protector for Sony T6...</td>\n",
              "      <td>Cell Phones &amp; Accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000GAWSBS</td>\n",
              "      <td>Casio Mens DBC310-1 Databank 300 Digital Watch...</td>\n",
              "      <td>Clothing, Shoes &amp; Jewelry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000040JOL</td>\n",
              "      <td>Factory-Reconditioned DEWALT DW260KR Heavy-Dut...</td>\n",
              "      <td>Tools &amp; Home Improvement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00006IB78</td>\n",
              "      <td>Energizer 2 in 1 Light This twoway light featu...</td>\n",
              "      <td>Health &amp; Personal Care</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ImgId  ...                 categories\n",
              "0  B000HYL1V6  ...      Arts, Crafts & Sewing\n",
              "1  B00006HXWY  ...  Cell Phones & Accessories\n",
              "2  B000GAWSBS  ...  Clothing, Shoes & Jewelry\n",
              "3  B000040JOL  ...   Tools & Home Improvement\n",
              "4  B00006IB78  ...     Health & Personal Care\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ6SNYq_tVVC"
      },
      "source": [
        "# Classify text with BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjmX4zTCkRK"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-YbjCkzw0yU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c134d7f-4a62-43b1-d968-d1d22d6ed78f"
      },
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.3 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 80 kB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 56.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 47.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 679 kB 41.6 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mkPpzbt0DFu"
      },
      "source": [
        "## Read Data and create the Dataset Input for the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhJKVPcgVh5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab26ebe-0699-4dbc-cac1-2fbfc29788fd"
      },
      "source": [
        "#Encode labels\n",
        "labels_onehot = pd.get_dummies(data_merge['categories']).values #on hot encoded labels\n",
        "labels_abs = np.argmax(labels_onehot, axis = 1)\n",
        "print(labels_onehot.shape)\n",
        "print(labels_abs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(46229, 21)\n",
            "[ 3  8  9 ...  3 11  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIx5MnclSqEx",
        "outputId": "30f6d387-d327-4b28-e6bf-3b779e6872e6"
      },
      "source": [
        "#to try something out short Dataset\n",
        "p=1000\n",
        "q=1200\n",
        "\n",
        "train_data_raw = data_merge['description'][:p].astype(\"str\")\n",
        "train_labels_onehot = labels_onehot[:p]\n",
        "train_labels_abs = labels_abs[:p]\n",
        "\n",
        "test_data_raw = data_merge['description'][p:q].astype(\"str\")\n",
        "test_labels_onehot = labels_onehot[p:q]\n",
        "test_labels_abs = labels_abs[p:q]\n",
        "\n",
        "print(train_data_raw.shape)\n",
        "print(train_labels_onehot.shape)\n",
        "\n",
        "print(test_data_raw.shape)\n",
        "print(test_labels_onehot.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "(1000, 21)\n",
            "(200,)\n",
            "(200, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmhRkVrek9KO",
        "outputId": "893db39b-9496-49b7-c05d-1d6321729050"
      },
      "source": [
        "#Train test Split:\n",
        "p = int((len(data_merge['description'])*80)/100)\n",
        "\n",
        "train_data_raw = data_merge['description'][:p].astype(\"str\")\n",
        "train_labels_onehot = labels_onehot[:p]\n",
        "\n",
        "test_data_raw = data_merge['description'][p:].astype(\"str\")\n",
        "test_labels_onehot = labels_onehot[p:]\n",
        "\n",
        "print(train_data_raw.shape)\n",
        "print(train_labels_onehot.shape)\n",
        "\n",
        "print(test_data_raw.shape)\n",
        "print(test_labels_onehot.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36983,)\n",
            "(36983, 21)\n",
            "(9246,)\n",
            "(9246, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRHUWM03Y2Ex"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "#keine Ahnung was da passiert aber ohne den ganzen scheiß funzts ned, hab ich teilweise aus dem letzten laborversuch\n",
        "train_ds=tf.data.Dataset.from_tensor_slices((train_data_raw,train_labels_onehot))\n",
        "train_ds= train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds=tf.data.Dataset.from_tensor_slices((test_data_raw,test_labels_onehot))\n",
        "test_ds= test_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHpVY9I9VcOy",
        "outputId": "63c9d36d-2def-4784-e722-bb1c099d5831"
      },
      "source": [
        "print(train_ds)\n",
        "print(test_ds)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None,), (None, 21)), types: (tf.string, tf.uint8)>\n",
            "<PrefetchDataset shapes: ((None,), (None, 21)), types: (tf.string, tf.uint8)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX8FtlpGJRE6"
      },
      "source": [
        "## Loading models from TensorFlow Hub\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "y8_ctG55-uTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ac3fcf-e0af-40bd-930a-fc61a9dba5ec"
      },
      "source": [
        "#@title Choose a BERT model to fine-tune\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WrcxxTRDdHi"
      },
      "source": [
        "## The preprocessing model\n",
        "\n",
        "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models, which implements this transformation using TF ops from the TF.text library. It is not necessary to run pure Python code outside your TensorFlow model to preprocess text.\n",
        "\n",
        "The preprocessing model must be the one referenced by the documentation of the BERT model, which you can read at the URL printed above. For BERT models from the drop-down above, the preprocessing model is selected automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SQi-jWd_jzq"
      },
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4naBiEE_cZX"
      },
      "source": [
        "Test of the preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9-zCzJpnuwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e984c0-aefb-4a23-ddaa-93519ad930ac"
      },
      "source": [
        "text_test = ['Test how the toknizer works']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 3231 2129 1996 2000 2243 3490 6290 2573  102    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqL7ihkN_862"
      },
      "source": [
        "you get 3 outputs from the preprocessing that a BERT model uses(`input_words_id`, `input_mask` and `input_type_ids`).\n",
        "\n",
        "- The `input_type_ids` only have one value (0) because this is a single sentence input. For a multiple sentence input, it would have one number for each input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKnLPSEmtp9i"
      },
      "source": [
        "## Using the BERT model\n",
        "\n",
        "Test of the Output of the BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXxYpK8ixL34"
      },
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OoF9mebuSZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e103b9-c2c1-47da-e077-337dd6e5be0f"
      },
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.9810978   0.7679234  -0.2940748   0.25524694 -0.50647515  0.48745096\n",
            "  0.99533564 -0.79871696 -0.39974886 -0.96710706  0.07749613 -0.9885023 ]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-1.6425401e-03  2.2269687e-01  6.5379763e-01 ... -6.9148624e-01\n",
            "   8.1796890e-01  1.6680063e+00]\n",
            " [-5.4676712e-01  3.2115445e-01  3.7330562e-01 ... -6.6274893e-01\n",
            "   4.7066234e-02  1.6138372e+00]\n",
            " [-2.3893352e-01  6.8877906e-01  2.3869738e-01 ... -5.7695937e-01\n",
            "  -2.7807638e-01  8.8928348e-01]\n",
            " ...\n",
            " [-1.4374524e-01  1.1608804e-01  1.0812830e+00 ... -5.4038906e-01\n",
            "   3.7956655e-01  1.3437957e+00]\n",
            " [ 1.3462247e-01  1.5471357e-01  3.6073285e-01 ...  1.1437862e-01\n",
            "   1.5190809e+00  2.8925160e-01]\n",
            " [-1.4504796e-01  3.6907578e-01  6.3715085e-02 ...  1.5245710e-01\n",
            "   1.6715612e+00  2.5315922e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm61jDrezAll"
      },
      "source": [
        "The BERT models return a map with 3 important keys: `pooled_output`, `sequence_output`, `encoder_outputs`:\n",
        "\n",
        "- `pooled_output` represents each input sequence as a whole. The shape is `[batch_size, H]`. It's an embedding for the description\n",
        "- `sequence_output` represents each input token in the context. The shape is `[batch_size, seq_length, H]`. This as a contextual embedding for every token in the descriptions.\n",
        "- `encoder_outputs` are the intermediate activations of the `L` Transformer blocks. `outputs[\"encoder_outputs\"][i]` is a Tensor of shape `[batch_size, seq_length, 1024]` with the outputs of the i-th Transformer block, for `0 <= i < L`. The last value of the list is equal to `sequence_output`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDNKfAXbDnJH"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aksj743St9ga"
      },
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(21, activation=None)(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs4yhFraBuGQ"
      },
      "source": [
        "Let's check that the model runs with the output of the preprocessing model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGMF8AZcB2Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af601527-dec4-4f0a-ed96-0b2a295e3ccf"
      },
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.650255   0.4811489  0.35293496 0.5938759  0.4382783  0.17050074\n",
            "  0.58273506 0.562034   0.21721181 0.59433997 0.59338635 0.44954896\n",
            "  0.75364476 0.58179843 0.29139686 0.33513713 0.6048201  0.6647708\n",
            "  0.43423292 0.44046146 0.19952495]], shape=(1, 21), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTUzNV2JE2G3"
      },
      "source": [
        "### Model structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EmzyHZXKIpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "49b70803-5146-4882-ac27-c81690f9ffc5"
      },
      "source": [
        "tf.keras.utils.plot_model(classifier_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbUWoZMwc302"
      },
      "source": [
        "## Model training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpJ3xcwDT56v"
      },
      "source": [
        "### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWPOZE-L3AgE"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77psrpfzbxtp"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "\"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (`num_warmup_steps`). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9eP2y9dbw32"
      },
      "source": [
        "epochs = 1\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqlarlpC_v0g"
      },
      "source": [
        "### Loading the BERT model and training\n",
        "\n",
        "Using the `classifier_model` you created earlier, you can compile the model with the loss, metric and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7GPDhR98jsD"
      },
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpBuV5j2cS_b"
      },
      "source": [
        "Note: training time will vary depending on the complexity of the BERT model you have selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtfDFAnN_Neu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64a2d20-ea9b-47f9-8c21-f0adff39fed7"
      },
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_ds,epochs=epochs)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "578/578 [==============================] - 165s 275ms/step - loss: 0.1673 - binary_accuracy: 0.9491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBthMlTSV8kn"
      },
      "source": [
        "### Evaluate the model\n",
        "\n",
        "Let's see how the model performs. Two values will be returned. Loss (a number which represents the error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slqB-urBV9sP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d8e7e6-0906-4286-97f8-f198508e38f2"
      },
      "source": [
        "loss, accuracy = classifier_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "145/145 [==============================] - 24s 164ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Loss: 0.0\n",
            "Accuracy: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZhPbDi68cSz"
      },
      "source": [
        "# Submission on Testdataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8y2VAeq5kjm"
      },
      "source": [
        "#merging the title and the description of the testdata together\n",
        "def merge_description_test (img_id, corpus):\n",
        "    data_merge = pd.DataFrame({'ImgId':img_id,\n",
        "                               'description':corpus,\n",
        "                               })\n",
        "    return data_merge\n",
        "\n",
        "#Create a dataset of from the pandas Dataframe\n",
        "def create_dataset_test(data):\n",
        "    # convert into string\n",
        "    test_data_raw = data['description'].astype(\"str\")\n",
        "    # create test dataset\n",
        "    test_ds=tf.data.Dataset.from_tensor_slices(test_data_raw)\n",
        "    test_ds= test_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "    test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    return test_ds"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3bg7XqA8mzK"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "4bWNERob8cAp",
        "outputId": "a0853360-ad0b-4a4d-913f-ab6ad1680b69"
      },
      "source": [
        "data_test = pd.read_csv('retail-products-classification/test.csv')\n",
        "print(data_test.shape)\n",
        "data_test.head(10)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10596, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImgId</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0006IK25E</td>\n",
              "      <td>Jacquard Textile Paint 2.25 Oz Pink</td>\n",
              "      <td>Jacquard Textile Pink Color in 2.25 ounces can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000GBRO16</td>\n",
              "      <td>Fimo Soft Polymer Clay 2 Ounces-8020-33 Brilli...</td>\n",
              "      <td>Fimo Soft Polymer Clay is easier to use than b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000H6OZGW</td>\n",
              "      <td>Sculpey III 2 Oz. Polymer Clay: Pale Pistachio</td>\n",
              "      <td>Sculpey 3 Polymer Clay is America's original o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000BR28KC</td>\n",
              "      <td>Sennelier Soft Pastel Turquoise Green 724</td>\n",
              "      <td>Handmade since 1900 Sennelier extra-fine soft ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0006IK27M</td>\n",
              "      <td>Jacquard Textile Colors sapphire blue</td>\n",
              "      <td>JACQUARD TEXTILE COLORS FABRIC PAINT - These e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B0000AZ6NS</td>\n",
              "      <td>Sudbury Heavy Duty ELASTO Sealant, White, CART...</td>\n",
              "      <td>Elastomeric marine sealant. One part, fast ski...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B0006IK268</td>\n",
              "      <td>Jacquard Textile Colors ruby red</td>\n",
              "      <td>JACQUARD TEXTILE COLORS FABRIC PAINT - These e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B000FNDZN6</td>\n",
              "      <td>Dylon Permanent Fabric Dye -Olive</td>\n",
              "      <td>Permanent Fabric Dye will not fade or wash awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>B000GBO8UG</td>\n",
              "      <td>Fimo Soft Polymer Clay 2 Ounces-8020-70 Sahara</td>\n",
              "      <td>Fimo Soft Polymer Clay is easier to use than b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>B0006IK2FE</td>\n",
              "      <td>Jacquard Textile Colors yellow ochre</td>\n",
              "      <td>JACQUARD TEXTILE COLORS FABRIC PAINT - These e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ImgId  ...                                        description\n",
              "0  B0006IK25E  ...  Jacquard Textile Pink Color in 2.25 ounces can...\n",
              "1  B000GBRO16  ...  Fimo Soft Polymer Clay is easier to use than b...\n",
              "2  B000H6OZGW  ...  Sculpey 3 Polymer Clay is America's original o...\n",
              "3  B000BR28KC  ...  Handmade since 1900 Sennelier extra-fine soft ...\n",
              "4  B0006IK27M  ...  JACQUARD TEXTILE COLORS FABRIC PAINT - These e...\n",
              "5  B0000AZ6NS  ...  Elastomeric marine sealant. One part, fast ski...\n",
              "6  B0006IK268  ...  JACQUARD TEXTILE COLORS FABRIC PAINT - These e...\n",
              "7  B000FNDZN6  ...  Permanent Fabric Dye will not fade or wash awa...\n",
              "8  B000GBO8UG  ...  Fimo Soft Polymer Clay is easier to use than b...\n",
              "9  B0006IK2FE  ...  JACQUARD TEXTILE COLORS FABRIC PAINT - These e...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SyqCCjfC8d7"
      },
      "source": [
        "#take the pictures to find descriptions with pictures\n",
        "test_images_path = 'retail-products-classification/test/test'\n",
        "test_corpus= []\n",
        "test_image_ids = []\n",
        "files = os.listdir(test_images_path)\n",
        "for img in files:\n",
        "    img_id = img.split('.')[0]\n",
        "    if img_id is not None:\n",
        "        try:\n",
        "            index = data_test[data_test['ImgId']==img_id].index.values[0]\n",
        "            row = data_test.iloc[index , :]\n",
        "            description = row[2]\n",
        "            title = row[1]\n",
        "            test_corpus.append(str(title) + ' ' + str(description))\n",
        "            test_image_ids.append(img_id)\n",
        "        except IndexError as error:\n",
        "            print(error)\n",
        "print(len(test_image_ids))\n",
        "print(len(test_corpus))\n",
        "#convert the stuff in a pandas"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAuEYHa0FNZk",
        "outputId": "e96672f3-55d6-4572-91d7-12df9c4cea0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6367\n",
            "6367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx9rIFS-8t1-"
      },
      "source": [
        "data_merge_test = merge_description_test(test_image_ids,test_corpus)\n",
        "test_ds_submission = create_dataset_test(data_merge_test)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XHFlirbHezL",
        "outputId": "4d4de4e6-e2c3-4d9a-e97d-753f2a93796a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "data_merge_test"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImgId</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0002IXOLC</td>\n",
              "      <td>EXTREME DISH WHEEL COARSE Kutzall Extreme grin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B00067TUK8</td>\n",
              "      <td>Cernit Oven-Bake Modeling Clay For Making Doll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B00006RVJL</td>\n",
              "      <td>Astonica 50302120 Two-Shelf Mini Greenhouse (D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B0002JMDXQ</td>\n",
              "      <td>Equus 3143 Ford Code Reader 1981-1995 Ford OBD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0002YV7J2</td>\n",
              "      <td>Triple Trolley Platform Cart 250 Lbs (RUB44000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6362</th>\n",
              "      <td>B0000AVVN6</td>\n",
              "      <td>Kenco 100 - lb. Straight Shooter Feeder System...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6363</th>\n",
              "      <td>1589943171</td>\n",
              "      <td>Runebound: Avatars of Kelnov inches When the D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6364</th>\n",
              "      <td>B000E6MHFQ</td>\n",
              "      <td>LG USB Data Cable Connect your handset to your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6365</th>\n",
              "      <td>B000FMYY2S</td>\n",
              "      <td>Black Viton Soft Tubing, 3/16&amp;quot; ID, 5/16&amp;q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6366</th>\n",
              "      <td>B0007VVGY6</td>\n",
              "      <td>Springmaid Waterproof Bassinet Changing Table ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6367 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           ImgId                                        description\n",
              "0     B0002IXOLC  EXTREME DISH WHEEL COARSE Kutzall Extreme grin...\n",
              "1     B00067TUK8  Cernit Oven-Bake Modeling Clay For Making Doll...\n",
              "2     B00006RVJL  Astonica 50302120 Two-Shelf Mini Greenhouse (D...\n",
              "3     B0002JMDXQ  Equus 3143 Ford Code Reader 1981-1995 Ford OBD...\n",
              "4     B0002YV7J2  Triple Trolley Platform Cart 250 Lbs (RUB44000...\n",
              "...          ...                                                ...\n",
              "6362  B0000AVVN6  Kenco 100 - lb. Straight Shooter Feeder System...\n",
              "6363  1589943171  Runebound: Avatars of Kelnov inches When the D...\n",
              "6364  B000E6MHFQ  LG USB Data Cable Connect your handset to your...\n",
              "6365  B000FMYY2S  Black Viton Soft Tubing, 3/16&quot; ID, 5/16&q...\n",
              "6366  B0007VVGY6  Springmaid Waterproof Bassinet Changing Table ...\n",
              "\n",
              "[6367 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnP6lcUC9oUl",
        "outputId": "11ebeec2-355a-4bed-8303-dfce85b68e50"
      },
      "source": [
        "pred_submission = classifier_model.predict(test_ds_submission)\n",
        "test_classes = np.argmax(pred_submission, axis = 1)\n",
        "print(test_classes)\n",
        "print(test_classes.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3 19 16 ...  0  7 12]\n",
            "(6367,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b-WTk9E-7aa"
      },
      "source": [
        "import csv\n",
        "with open('submission.csv', mode='w') as metadata_file:\n",
        "    metadata_writer = csv.writer(metadata_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    metadata_writer.writerow(['ImgId', 'category'])\n",
        "    for i, val in enumerate(test_classes):\n",
        "        metadata_writer.writerow([data_merge_test['ImgId'][i], test_classes[i]])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uttWpgmSfzq9"
      },
      "source": [
        "### Plot the accuracy and loss over time\n",
        "\n",
        "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiythcODf0xo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "8c855231-86d5-4afe-e0eb-373442f31d26"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "# plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'binary_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-27d873b9ddf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_binary_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzJZCo-cf-Jf"
      },
      "source": [
        "In this plot, the red lines represent the training loss and accuracy, and the blue lines are the validation loss and accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtn7jewb6dg4"
      },
      "source": [
        "## Export for inference\n",
        "\n",
        "Now you just save your fine-tuned model for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShcvqJAgVera"
      },
      "source": [
        "dataset_name = 'imdb'\n",
        "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
        "\n",
        "classifier_model.save(saved_model_path, include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbI25bS1vD7s"
      },
      "source": [
        "Let's reload the model, so you can try it side by side with the model that is still in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUEWVskZjEF0"
      },
      "source": [
        "reloaded_model = tf.saved_model.load(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyTappHTvNCz"
      },
      "source": [
        "Here you can test your model on any sentence you want, just add to the examples variable below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBWzH6exlCPS"
      },
      "source": [
        "def print_my_examples(inputs, results):\n",
        "  result_for_printing = \\\n",
        "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
        "                         for i in range(len(inputs))]\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()\n",
        "\n",
        "\n",
        "examples = [\n",
        "    'this is such an amazing movie!',  # this is the same sentence tried earlier\n",
        "    'The movie was great!',\n",
        "    'The movie was meh.',\n",
        "    'The movie was okish.',\n",
        "    'The movie was terrible...'\n",
        "]\n",
        "\n",
        "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
        "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
        "\n",
        "print('Results from the saved model:')\n",
        "print_my_examples(examples, reloaded_results)\n",
        "print('Results from the model in memory:')\n",
        "print_my_examples(examples, original_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cOmih754Y_M"
      },
      "source": [
        "If you want to use your model on [TF Serving](https://www.tensorflow.org/tfx/guide/serving), remember that it will call your SavedModel through one of its named signatures. In Python, you can test them as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FdVD3973S-O"
      },
      "source": [
        "serving_results = reloaded_model \\\n",
        "            .signatures['serving_default'](tf.constant(examples))\n",
        "\n",
        "serving_results = tf.sigmoid(serving_results['classifier'])\n",
        "\n",
        "print_my_examples(examples, serving_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4gN1KwReLPN"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "As a next step, you can try [Solve GLUE tasks using BERT on a TPU tutorial](https://www.tensorflow.org/text/tutorials/bert_glue), which runs on a TPU and shows you how to work with multiple inputs."
      ]
    }
  ]
}